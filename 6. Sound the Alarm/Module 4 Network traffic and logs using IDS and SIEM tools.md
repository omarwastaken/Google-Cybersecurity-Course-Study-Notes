# Overview of logs

## The Importance of Logs

### Introduction

Logs are crucial in detecting unusual or malicious activity within an organization. They provide visibility into an environment by recording events that occur on network systems or devices.

### What Are Logs?

- **Logs**: Records of events within an organization's systems.
- **Log Files**: Files where system activities are recorded.
- **Events**: Observable occurrences on a network system or device.

### Importance of Logs

## Logs are valuable for security analysts during incident investigations. They record details of what, where, and when an event occurred on the network, including:

- Date and time
- Location
- Action performed
- Names of users or systems involved

These details help analysts build a timeline and story around various events to understand what happened.

### Log Analysis

Log analysis is the process of examining logs to identify events of interest. Due to the large volume of log data generated, it's important to be selective in what data is logged to ensure efficient analysis.

### SIEM Technology

## Security Information and Event Management (SIEM) tools provide a high-level overview of network activities by:

- Collecting data from multiple sources
- Aggregating data into a centralized location
- Normalizing diverse log formats into a single preferred format

SIEM tools help process large log volumes in real-time, allowing security analysts to quickly search and perform log analysis.

### Log Collection

Logs are collected by software known as log forwarders, which automatically forward them to a centralized log repository for storage.

### Types of Log Data Sources

## Different devices and systems create logs, leading to various log data sources in an environment:

- **Network Logs**: Generated by devices like proxies, routers, switches, and firewalls.
- **System Logs**: Generated by operating systems.
- **Application Logs**: Related to software applications.
- **Security Logs**: Generated by security tools like IDS or IPS.
- **Authentication Logs**: Record login attempts.

### Example of a Network Log

Here is an example of a network log from a router:

`ALLOWED  SRC=192.168.1.1  DST=google.com  TIMESTAMP=2022-01-01 12:00:00`

## Fields in the log entry:

- **Action**: Specifies "ALLOW," indicating that the router's firewall settings allowed access.
- **Source**: Lists an IP address (192.168.1.1).
- **Destination**: Specifies the destination ([google.com](http://google.com/)).
- **Timestamp**: Provides the exact date and time of the action (2022-01-01 12:00:00).

### Summary

Logs are essential for security monitoring and troubleshooting. They help security professionals detect, investigate, and respond to incidents efficiently. By understanding the importance and proper handling of logs, organizations can enhance their security posture and respond to threats more effectively.

## Best Practices for Log Collection and Management

Understanding best practices related to log collection and management will help improve log searches and better support efforts in identifying and resolving security incidents.

### Logs

Logs are records of events that occur within an organization's systems. They contain log entries detailing information about specific events or occurrences. Logs provide valuable insights beyond troubleshooting, such as aiding security teams in incident investigations.

### Types of Logs

Depending on the data source, different log types can be produced. Here are some common log types:

- **Network Logs**: Generated by devices like firewalls, routers, or switches.
- **System Logs**: Generated by operating systems such as Chrome OS™, Windows, Linux, or macOS®.
- **Application Logs**: Generated by software applications and contain information relating to events within the application.
- **Security Logs**: Generated by various devices or systems such as antivirus software and intrusion detection systems, containing security-related information.
- **Authentication Logs**: Generated whenever authentication occurs, such as successful login attempts.

### Log Details

Logs typically contain information such as date, time, location, action, and author of the action. Here is an example of an authentication log:

`Login Event [05:45:15] User1 Authenticated successfully`

Verbose logging records additional, detailed information beyond the default log recording:

`Login Event [2022/11/16 05:45:15.892673] auth_performer.cc:470 User1 Authenticated successfully from device1 (192.168.1.2)`

### Log Management

Log management involves the process of collecting, storing, analyzing, and disposing of log data. Effective log management helps organizations derive the most value from their logs.

#### What to Log

Choosing what to log is crucial. Not all data needs to be logged, and overlogging can have several disadvantages:

- **Storage and Maintenance Costs**: Excessive logs can increase costs.
- **Performance Issues**: Overlogging can affect system performance and usability.
- **Search and Identification Difficulties**: Too many logs can make it hard to find important events.

#### Log Retention

Regulatory requirements may mandate log retention for specific periods. Different industries have different regulations:

- **Public Sector**: Federal Information Security Modernization Act (FISMA)
- **Healthcare**: Health Insurance Portability and Accountability Act of 1996 (HIPAA)
- **Financial Services**: Payment Card Industry Data Security Standard (PCI DSS), Gramm-Leach-Bliley Act (GLBA), and Sarbanes-Oxley Act of 2002 (SOX)

#### Log Protection

Protecting logs is vital for maintaining their integrity. Storing logs in a centralized log server is one way to maintain log integrity:

- **Centralized Log Server**: Logs are sent to a dedicated server instead of being stored on a local machine, making it harder for attackers to access them.

### Key Takeaways

Understanding how to properly collect, store, and protect logs is integral to incident investigations. Having a detailed plan for log management helps improve the usefulness of logs and resource efficiency.

### Sample Table: Log Types and Sources

|**Log Type**|**Source**|
|---|---|
|Network Logs|Firewalls, routers, switches|
|System Logs|Operating systems (e.g., Windows, Linux)|
|Application Logs|Software applications|
|Security Logs|Antivirus, IDS, IPS|
|Authentication Logs|Login attempts|

### Sample Code Block: Example of a Network Log

`ALLOWED  SRC=192.168.1.1  DST=google.com  TIMESTAMP=2022-01-01 12:00:00`

## Variations of Logs

Logs are essential records of events or activities that happen on a network or system. As a security analyst, you'll be responsible for interpreting these logs to understand and respond to incidents. Logs can be generated from various data sources, such as network devices, operating systems, and applications, and they come in different formats. Each format provides critical information for understanding system and network activities.

### Common Log Formats

Logs are similar to receipts in that they record significant details about transactions or events. They contain information like timestamps, system characteristics, such as IP addresses, and descriptions of events, including the actions taken and who performed the actions. Logs can be either human-readable or machine-readable, verbose or simple. Here are some commonly used log formats:

### Syslog

**Syslog** is both a protocol and a log format. It is widely used for transporting and writing logs. A Syslog entry includes three main sections:

1. **Header**: Contains data fields like Timestamp, Hostname, Application name, and Message ID.
2. **Structured-data**: Contains additional data in key-value pairs.
3. **Message**: Contains the detailed log message about the event.

Example of a Syslog entry:

`<34>1 2023-05-21T10:15:30.003Z mymachine.example.com appname - ID47 [exampleSDID@32473 eventSource="Application"] This is a log entry!`

### JSON

**JavaScript Object Notation (JSON)** is a text-based format designed for easy reading and writing. It structures data using key-value pairs, making it simple and human-readable.

Example of a JSON log:

`{   "Alert" : "Malware" ,   "Timestamp" : "2023-05-21T10:15:30.003Z" ,   "SourceIP" : "192.168.1.1" ,   "DestinationIP" : "10.0.0.1" ,   "Message" : "Malware detected on host." }`

### XML

**eXtensible Markup Language (XML)** is used for storing and transmitting data. It uses tags and attributes to structure data.

Example of an XML log:

`<log>   <firstName>John</firstName>   <lastName>Doe</lastName>   <employeeID>12345</employeeID>   <dateJoined>2022-01-01</dateJoined> </log>`

### CSV

**Comma Separated Values (CSV)** is a format that uses separators, such as commas, to separate data values. It is commonly used for tabular data.

Example of a CSV log:

`Timestamp, SourceIP, DestinationIP, Action, Message 2023-05-21T10:15:30.003Z, 192.168.1.1, 10.0.0.1, ALLOW, Connection allowed to google.com`

### Key Takeaways

- **Syslog**: Commonly used protocol and format for logging, structured with headers, structured-data, and messages.
- **JSON**: Human-readable format using key-value pairs, ideal for simplicity and readability.
- **XML**: Uses tags and attributes for data storage and transmission, suitable for structured data.
- **CSV**: Uses commas to separate values, excellent for tabular data representation.

## Overview of Log File Formats

You’ve learned about how logs record events that happen on a network or system. In security, logs provide key details about activities that occurred across an organization, like who signed into an application at a specific point in time. As a security analyst, you’ll use **log analysis**, which is the process of examining logs to identify events of interest. It’s important to know how to read and interpret different log formats so that you can uncover the key details surrounding an event and identify unusual or malicious activity. In this reading, you’ll review the following log formats:

- JSON
- Syslog
- XML
- CSV
- CEF

## JavaScript Object Notation (JSON)

JavaScript Object Notation (JSON) is a file format that is used to store and transmit data. JSON is known for being lightweight and easy to read and write. It is used for transmitting data in web technologies and is also commonly used in cloud environments. JSON syntax is derived from JavaScript syntax. If you are familiar with JavaScript, you might recognize that JSON contains components from JavaScript including:

- Key-value pairs
- Commas
- Double quotes
- Curly brackets
- Square brackets

### Key-Value Pairs

A **key-value pair** is a set of data that represents two linked items: a key and its corresponding value. A key-value pair consists of a key followed by a colon, and then followed by a value. An example of a key-value pair is `"Alert": "Malware"`.

**Note**: For readability, it is recommended that key-value pairs contain a space before or after the colon that separates the key and value.

### Commas

Commas are used to separate data. For example: `"Alert": "Malware", "Alert code": 1090, "severity": 10`.

### Double Quotes

Double quotes are used to enclose _text_ data, which is also known as a string. For example: `"Alert": "Malware"`. Data that contains numbers _is not_ enclosed in quotes, like this: `"Alert code": 1090`.

### Curly Brackets

Curly brackets enclose an **object**, which is a data type that stores data in a comma-separated list of key-value pairs. Objects are often used to describe multiple properties for a given key. JSON log entries start and end with a curly bracket. In this example, `User` is the object that contains multiple properties:

`{   "User" : {     "id" : "1234" ,     "name" : "user" ,     "role" : "engineer"   } }`

### Square Brackets

Square brackets are used to enclose an **array**, which is a data type that stores data in a comma-separated ordered list. Arrays are useful when you want to store data as an ordered collection, for example: `["Administrators", "Users", "Engineering"]`.

## Syslog

Syslog is a standard for logging and transmitting data. It can be used to refer to any of its three different capabilities:

1. **Protocol**: The syslog protocol is used to transport logs to a centralized log server for log management. It uses port 514 for plaintext logs and port 6514 for encrypted logs.
2. **Service**: The syslog service acts as a log forwarding service that consolidates logs from multiple sources into a single location. The service works by receiving and then forwarding any syslog log entries to a remote server.
3. **Log Format**: The syslog log format is one of the most commonly used log formats that you will be focusing on. It is the native logging format used in Unix® systems. It consists of three components: a header, structured-data, and a message.

### Syslog Log Example

Here is an example of a syslog entry that contains all three components: a header, followed by structured-data, and a message:

`<236>1 2022-03-21T01:11:11.003Z virtual.machine.com evntslog - ID01 [user@32473 iut="1" eventSource="Application" eventID="9999"] This is a log entry!`

#### Header

The header contains details like the timestamp; the hostname, which is the name of the machine that sends the log; the application name; and the message ID.

- **Timestamp**: The timestamp in this example is `2022-03-21T01:11:11.003Z`, where `2022-03-21` is the date in YYYY-MM-DD format. `T` is used to separate the date and the time. `01:11:11.003` is the 24-hour format of the time and includes the number of milliseconds 003. `Z` indicates the timezone, which is Coordinated Universal Time (UTC).
- **Hostname**: `virtual.machine.com`
- **Application**: `evntslog`
- **Message ID**: `ID01`

#### Structured-data

The structured-data portion of the log entry contains additional logging information. This information is enclosed in square brackets and structured in key-value pairs. Here, there are three keys with corresponding values: `[user@32473 iut="1" eventSource="Application" eventID="9999"]`.

#### Message

The message contains a detailed log message about the event. Here, the message is `This is a log entry!`.

#### Priority (PRI)

The priority (PRI) field indicates the urgency of the logged event and is contained with angle brackets. In this example, the priority value is `<236>`. Generally, the lower the priority level, the more urgent the event is.

**Note**: Syslog headers can be combined with JSON, and XML formats. Custom log formats also exist.

## XML (eXtensible Markup Language)

XML (eXtensible Markup Language) is a language and a format used for storing and transmitting data. XML is a native file format used in Windows systems. XML syntax uses the following:

- Tags
- Elements
- Attributes

### Tags

XML uses tags to store and identify data. Tags are pairs that must contain a start tag and an end tag. The start tag encloses data with angle brackets, for example `<tag>`, whereas the end of a tag encloses data with angle brackets and a forward slash like this: `</tag>`.

### Elements

XML elements include _both_ the data contained inside of a tag and the tags itself. All XML entries must contain at least one root element. Root elements contain other elements that sit underneath them, known as child elements.

Here is an example:

`<Event>   <EventID>4688</EventID>   <Version>5</Version> </Event>`

In this example, `<Event>` is the root element and contains two child elements `<EventID>` and `<Version>`. There is data contained in each respective child element.

### Attributes

XML elements can also contain attributes. Attributes are used to provide additional information about elements. Attributes are included as the second part of the tag itself and must always be quoted using either single or double quotes.

For example:

`<EventData>   <Data Name='SubjectUserSid'>S-2-3-11-160321</Data>   <Data Name='SubjectUserName'>JSMITH</Data>   <Data Name='SubjectDomainName'>ADCOMP</Data>   <Data Name='SubjectLogonId'>0x1cf1c12</Data>   <Data Name='NewProcessId'>0x1404</Data> </EventData>`

In the first line for this example, the tag is `<Data>` and it uses the attribute `Name='SubjectUserSid'` to describe the data enclosed in the tag `S-2-3-11-160321`.

## CSV (Comma Separated Value)

CSV (Comma Separated Value) uses commas to separate data values. In CSV logs, the position of the data corresponds to its field name, but the field names themselves might not be included in the log. It’s critical to understand what fields the source device (like an IPS, firewall, scanner, etc.) is including in the log.

Here is an example:

`2009-11-24T21:27:09.534255,ALERT,192.168.2.7, 1041,x.x.250.50,80,TCP,ALLOWED,1:2001999:9,"ET MALWARE BTGrab.com Spyware Downloading Ads",1`

## CEF (Common Event Format)

**Common Event Format (CEF)** is a log format that uses key-value pairs to structure data and identify fields and their corresponding values. The CEF syntax is defined as containing the following fields:

`CEF:Version|Device Vendor|Device Product|Device Version|Signature ID|Name|Severity|Extension`

Fields are all separated with a pipe character `|`. However, anything in the Extension part of the CEF log entry must be written in a key-value format. Syslog is a common method used to transport logs like CEF. When Syslog is used a timestamp and hostname will be prepended to the CEF message. Here is an example of a CEF log entry that details malicious activity relating to a worm infection:

`Sep 29 08:26:10 host CEF:1|Security|threatmanager|1.0|100|worm successfully stopped|10|src=10.0.0.2 dst=2.1.2.2 spt=1232`

### Breakdown of the Fields

- **Syslog Timestamp**: Sep 29 08:26:10
- **Syslog Hostname**: host
- **Version**: CEF:1
- **Device Vendor**: Security
- **Device Product**: threatmanager
- **Device Version**: 1.0
- **Signature ID**: 100
- **Name**: worm successfully stopped
- **Severity**: 10
- **Extension**: This field contains data written as key-value pairs. There are two IP addresses, `src=10.0.0.2` and `dst=2.1.2.2`, and a source port number `spt=1232`. Extensions are not required and are optional to add.

This log entry contains details about a Security application called `threatmanager` that successfully stopped a worm from spreading from the internal network at `10.0.0.2` to the external network `2.1.2.2` through the port `1232`. A high severity level of `10` is reported.

**Note**: Extensions and syslog prefix are optional to add to a CEF log.

## Key Takeaways

There is no standard format used in logging, and many different log formats exist. As a security analyst, you will analyse logs that originate from different sources. Knowing how to interpret different log formats will help you determine key information that you can use to support your investigations.

# Overview of intrusion detection systems (IDS)

## Security Monitoring with Detection Tools

Detection requires data, and this data can come from various data sources. You've already explored how different devices produce logs. Now we'll examine how different detection technologies monitor devices and log different types of system activity, like network and endpoint telemetry.

### Telemetry

Telemetry is the collection and transmission of data for analysis. While logs record events occurring on systems, telemetry describes the data itself. For example, packet captures are considered network telemetry. For security professionals, logs and telemetry are sources of evidence that can be used to answer questions during investigations.

### Intrusion Detection System (IDS)

An **Intrusion Detection System (IDS)** is an application that monitors activity and alerts on possible intrusions. This includes monitoring different parts of a system or network like an endpoint.

#### Host-Based Intrusion Detection System (HIDS)

An **endpoint** is any device connected to a network, such as a laptop, tablet, desktop computer, or smartphone. Endpoints are entry points into a network, which makes them key targets for malicious actors looking to gain unauthorized access to a system.

To monitor endpoints for threats or attacks, a **host-based intrusion detection system (HIDS)** can be used. It's an application that monitors the activity of the host on which it's installed. To clarify, a host is any device that communicates with other devices on a network, similar to an endpoint. Host-based intrusion detection systems are installed as an agent on a single host, such as a laptop computer or a server. Depending on its configuration, host-based intrusion detection systems will monitor the host on which it's installed to detect suspicious activity. Once something has been detected, it records output as logs and an alert gets generated.

#### Network-Based Intrusion Detection System (NIDS)

A **network-based intrusion detection system (NIDS)** collects and analyses network traffic and network data. Network-based intrusion detection systems work similar to packet sniffers because they analyse network traffic and network data at a specific point in the network.

It's common to deploy multiple IDS sensors at different points in the network to achieve adequate visibility. When suspicious or unusual network activity is detected, the network-based intrusion detection system logs it and generates an alert. In this example, the network-based intrusion detection system is monitoring the traffic that's both coming from and going to the internet.

### Detection Methods

#### Signature Analysis

Intrusion detection systems use different types of detection methods. One of the most common methods is **signature analysis**. Signature analysis is a detection method used to find events of interest. A signature specifies a set of rules that an IDS refers to when it monitors activity. If the activity matches the rules in the signature, the IDS logs it and sends out an alert. For example, a signature can be written to generate an alert if a failed login on a system happens three times in a row, which suggests a possible password attack.

### IDS Logs

Before alerts are generated, the activity must be logged. IDS technologies record the information of the devices, systems, and networks which they monitor as IDS logs. IDS logs can then be sent, stored, and analysed in a centralized log repository like a SIEM (Security Information and Event Management).

### Example of IDS Logs

Here is an example of a typical IDS log entry:

`<Alert>   <Timestamp>2023-03-21T01:11:11.003Z</Timestamp>   <SourceIP>192.168.1.10</SourceIP>   <DestinationIP>192.168.1.20</DestinationIP>   <EventType>FailedLogin</EventType>   <Details>Failed login attempt detected from 192.168.1.10 to 192.168.1.20</Details> </Alert>`

### Key Takeaways

- **Telemetry**: The collection and transmission of data for analysis.
- **IDS**: Monitors activity and alerts on possible intrusions. Includes HIDS and NIDS.
- **Signature Analysis**: Detection method used by IDS to find events of interest.
- **IDS Logs**: Recorded information of monitored devices, systems, and networks, stored and analysed in a centralized log repository.

## Detection Tools and Techniques

In this reading, you’ll examine the different types of intrusion detection system (IDS) technologies and the alerts they produce. You’ll also explore the two common detection techniques used by detection systems. Understanding the capabilities and limitations of IDS technologies and their detection techniques will help you interpret security information to identify, analyse, and respond to security events.

As you’ve learned, an **Intrusion Detection System (IDS)** is an application that monitors system activity and alerts on possible intrusions. IDS technologies help organizations monitor the activity that happens on their systems and networks to identify indications of malicious activity. Depending on the location you choose to set up an IDS, it can be either host-based or network-based.

### Host-Based Intrusion Detection System (HIDS)

A **host-based intrusion detection system (HIDS)** is an application that monitors the activity of the host on which it's installed. A HIDS is installed as an agent on a host. A host is also known as an endpoint, which is any device connected to a network like a computer or a server.

Typically, HIDS agents are installed on all endpoints and used to monitor and detect security threats. A HIDS monitors internal activity happening on the host to identify any unauthorized or abnormal behavior. If anything unusual is detected, such as the installation of an unauthorized application, the HIDS logs it and sends out an alert.

In addition to monitoring inbound and outbound traffic flows, HIDS can have additional capabilities, such as monitoring file systems, system resource usage, user activity, and more.

This diagram shows a HIDS tool installed on a computer. The dotted circle around the host indicates that it is only monitoring the local activity on the single computer on which it’s installed.

### Network-Based Intrusion Detection System (NIDS)

A **network-based intrusion detection system (NIDS)** is an application that collects and monitors network traffic and network data. NIDS software is installed on devices located at specific parts of the network that you want to monitor. The NIDS application inspects network traffic from different devices on the network. If any malicious network traffic is detected, the NIDS logs it and generates an alert.

This diagram shows a NIDS that is installed on a network. The highlighted circle around the server and computers indicates that the NIDS is installed on the server and is monitoring the activity of the computers.

### Combining HIDS and NIDS

Using a combination of HIDS and NIDS to monitor an environment can provide a multi-layered approach to intrusion detection and response. HIDS and NIDS tools provide a different perspective on the activity occurring on a network and the individual hosts that are connected to it. This helps provide a comprehensive view of the activity happening in an environment.

## Detection Techniques

Detection systems can use different techniques to detect threats and attacks. The two types of detection techniques that are commonly used by IDS technologies are **signature-based analysis** and **anomaly-based analysis**.

### Signature-Based Analysis

**Signature analysis**, or **signature-based analysis**, is a detection method that is used to find events of interest. A signature is a pattern that is associated with malicious activity. Signatures can contain specific patterns like a sequence of binary numbers, bytes, or even specific data like an IP address.

Previously, you explored the Pyramid of Pain, which is a concept that prioritizes the different types of indicators of compromise (IoCs) associated with an attack or threat, such as IP addresses, tools, tactics, techniques, and more. IoCs and other indicators of attack can be useful for creating targeted signatures to detect and block attacks.

Different types of signatures can be used depending on which type of threat or attack you want to detect. For example, an anti-malware signature contains patterns associated with malware. This can include malicious scripts that are used by the malware. IDS tools will monitor an environment for events that match the patterns defined in this malware signature. If an event matches the signature, the event gets logged and an alert is generated.

#### Advantages of Signature-Based Analysis

- **Low rate of false positives**: Signature-based analysis is very efficient at detecting known threats because it is simply comparing activity to signatures. This leads to fewer false positives. Remember that a false positive is an alert that incorrectly detects the presence of a threat.

#### Disadvantages of Signature-Based Analysis

- **Signatures can be evaded**: Signatures are unique, and attackers can modify their attack behaviors to bypass the signatures. For example, attackers can make slight modifications to malware code to alter its signature and avoid detection.
- **Signatures require updates**: Signature-based analysis relies on a database of signatures to detect threats. Each time a new exploit or attack is discovered, new signatures must be created and added to the signature database.
- **Inability to detect unknown threats**: Signature-based analysis relies on detecting known threats through signatures. Unknown threats can't be detected, such as new malware families or zero-day attacks, which are exploits that were previously unknown.

### Anomaly-Based Analysis

**Anomaly-based analysis** is a detection method that identifies abnormal behavior. There are two phases to anomaly-based analysis: a training phase and a detection phase. In the training phase, a baseline of normal or expected behavior must be established. Baselines are developed by collecting data that corresponds to normal system behavior. In the detection phase, the current system activity is compared against this baseline. Activity that happens outside of the baseline gets logged, and an alert is generated.

#### Advantages of Anomaly-Based Analysis

- **Ability to detect new and evolving threats**: Unlike signature-based analysis, which uses known patterns to detect threats, anomaly-based analysis can detect unknown threats.

#### Disadvantages of Anomaly-Based Analysis

- **High rate of false positives**: Any behavior that deviates from the baseline can be flagged as abnormal, including non-malicious behaviors. This leads to a high rate of false positives.
- **Pre-existing compromise**: The existence of an attacker during the training phase will include malicious behavior in the baseline. This can lead to missing a pre-existing attacker.

## Key Takeaways

IDS technologies are an essential security tool that you will encounter in your security journey. To recap, a NIDS monitors an entire network, whereas a HIDS monitors individual endpoints. IDS technologies generate different types of alerts. Lastly, IDS technologies use different detection techniques like signature-based or anomaly-based analysis to identify malicious activity.

## Components of a Detection Signature

As a security analyst, you may be tasked with writing, customizing, or testing signatures. To do this, you'll use IDS tools. This section will examine signature syntax and by the end, you'll be able to read a signature.

A signature specifies detection rules. These rules outline the types of network intrusions you want an IDS to detect. For example, a signature can be written to detect and alert on suspicious traffic attempting to connect to a port.

Rule language differs depending on different network intrusion detection systems (NIDS). Generally, NIDS rules consist of three components: an action, a header, and rule options. Let's examine each of these three components in more detail.

### Action

Typically, the action is the first item specified in a signature. This determines the action to take if the rule criteria matches are met. Actions differ across NIDS rule languages, but some common actions are:

- **Alert**: Generates an alert if the rule criteria are met.
- **Pass**: Ignores the traffic if the rule criteria are met.
- **Reject**: Rejects the traffic if the rule criteria are met.

Example:

`alert tcp any any -> 192.168.1.0/24 80 (msg:"Possible HTTP Traffic"; sid:1000001; rev:1;)`

In this example, the action is `alert`.

### Header

The header defines the signature's network traffic. This includes information such as source and destination IP addresses, source and destination ports, protocols, and traffic direction.

Example:

`alert tcp 10.120.170.17 any -> 133.113.202.181 80`

- **Protocol**: TCP
- **Source IP address**: 10.120.170.17
- **Source port number**: any
- **Traffic direction**: `->` (indicating from source to destination)
- **Destination IP address**: 133.113.202.181
- **Destination port number**: 80

### Rule Options

The rule options let you customize signatures with additional parameters. There are many different options available to use. For instance, you can set options to match the content of a network packet to detect malicious payloads. Malicious payloads reside in a packet's data and perform malicious activity like deleting or encrypting data.

Configuring rule options helps in narrowing down network traffic, so you can find exactly what you're looking for. Typically, rule options are separated by semi-colons and enclosed in parentheses.

Example:

`(msg:"This is a message"; sid:1000001; rev:1;)`

- **msg**: Provides the alert's text. In this case, the alert will print out the text: "This is a message."
- **sid**: Stands for signature ID. This attaches a unique ID to each signature. Here, the ID is `1000001`.
- **rev**: Stands for revision. Each time a signature is updated or changed, the revision number changes. Here, the number `1` means it's the first version of the signature.

### Complete Example

Combining all the components, a complete NIDS signature might look like this:

`alert tcp 10.120.170.17 any -> 133.113.202.181 80 (msg:"This is a message"; sid:1000001; rev:1;)`

## In this example:

- **Action**: `alert`
- **Header**: `tcp 10.120.170.17 any -> 133.113.202.181 80`
- **Rule Options**: `(msg:"This is a message"; sid:1000001; rev:1;)`

## Key Takeaways

- **Action**: Defines what action the IDS should take if the rule criteria are met.
- **Header**: Specifies the network traffic details including source/destination IP addresses, ports, protocol, and traffic direction.
- **Rule Options**: Additional parameters that provide detailed criteria for the signature, including message text, signature ID, and revision number.

## Examine Signatures with Suricata

Previously, you learned about signature-based analysis and how to read signatures used in network-based intrusion detection systems (NIDS). Here, we'll use an open-source signature-based IDS called Suricata to examine a signature. Many NIDS technologies come with pre-written signatures, which serve as customizable templates similar to templates available in a word processor. These signature templates provide a starting point for writing and defining your rules, but you can also write and add your own rules. Let's examine a pre-written signature through Suricata.

### Accessing Suricata Configuration Files

On a Linux machine running Ubuntu, Suricata is already installed. Let's examine some of its files by changing directories to the `etc` directory and into the `suricata` directory. This is where all of Suricata's configuration files are located.

`cd /etc/suricata`

Next, we'll use the `ls` command to list the contents of the `suricata` directory. There's a couple of different files in here, but we'll focus on the `rules` folder. This is where the pre-written signatures are. You can also add custom signatures here. We'll use the `cd` command followed by the name of the folder to navigate to that folder.

`ls cd rules`

Using the `ls` command again, we can observe that the folder contains some rule templates for different protocols and services.

`ls`

### Examining the Custom Rules File

Let's examine the `custom.rules` file using the `less` command. As a quick refresher, the `less` command returns the content of a file one page at a time, making it easy to move forward and backward through the content.

`less custom.rules`

We'll use the arrow key to scroll up. Lines that begin with a pound sign (`#`) are comments meant to provide context for those who read them and are ignored by Suricata. The first line says "Custom rules example for HTTP connection." This tells us that this file contains custom rules for HTTP connections. We can observe that there's a signature.

### Breakdown of a Signature

The first word specifies the signature's **Action**. For this signature, the action is `alert`. This means that the signature generates an alert when all of the conditions are met. The next part of the signature is the **Header**. It specifies the protocol `http`. The source IP address is `HOME_NET` and the source port is defined as `ANY`. The arrow (`->`) indicates the direction of traffic coming from the home network and going to the destination IP address `EXTERNAL_NET` and `ANY` destination port.

`alert http $HOME_NET any -> $EXTERNAL_NET any`

So far, we know that this signature triggers an alert when it detects any HTTP traffic leaving the home network and going to the external network.

### Rule Options

The last part of the signature includes the **Rule Options**. They're enclosed in parentheses and separated by semicolons. There are many options listed here, but we'll focus on the `msg`, `flow`, and `content` options.

`(msg:"GET on wire"; flow:established; content:"GET"; sid:1000001; rev:1;)`

- **msg**: This option will show the message "GET on wire" once the alert is triggered.
- **flow**: The `flow` option is used to match the direction of network traffic flow. Here, it's `established`, meaning a connection has been successfully made.
- **content**: The `content` option inspects the content of a packet. Here, between the quotation marks, the text `GET` is specified. `GET` is an HTTP request used to retrieve and request data from a server. This means the signature will match if a network packet contains the text `GET`, indicating a request.

### Summary

To summarize, this signature alerts anytime Suricata observes the text `GET` in an HTTP connection from the home network going to the external network. Every environment is different, and in order for an IDS to be effective, signatures must be tested and tailored. As a security analyst, you may test, modify, or create IDS signatures to improve the detection of threats in an environment and reduce the likelihood of false positives.

### Key Takeaways

- **Action**: Defines what action the IDS should take if the rule criteria are met.
- **Header**: Specifies the network traffic details including source/destination IP addresses, ports, protocol, and traffic direction.
- **Rule Options**: Additional parameters that provide detailed criteria for the signature, including message text, signature ID, and revision number.

## Examine Suricata Logs

Suricata, an open-source network threat detection engine, generates logs in a format known as EVE JSON. EVE stands for Extensible Event Format, and JSON stands for JavaScript Object Notation. JSON uses key-value pairs, which simplifies both searching and extracting text from log files. Suricata generates two types of log data: alert logs and network telemetry logs. Understanding these logs is essential for security investigations.

### EVE JSON Format

EVE JSON format is used by Suricata to structure its log data. The format is efficient for parsing and analysis, providing clear, structured information about events.

### Types of Logs

Suricata generates two primary types of logs:

1. **Alert Logs**
2. **Network Telemetry Logs**

#### Alert Logs

Alert logs contain information relevant to security investigations. These logs are typically generated by signatures that have triggered an alert, capturing details about suspicious or malicious activity on the network.

**Example of an Alert Log:**

```json
{
  "timestamp": "2023-01-01T12:34:56.789012Z",
  "event_type": "alert",
  "src_ip": "192.168.1.10",
  "src_port": 443,
  "dest_ip": "10.0.0.5",
  "dest_port": 8080,
  "proto": "TCP",
  "alert": {
    "action": "allowed",
    "gid": 1,
    "signature_id": 1000001,
    "rev": 1,
    "signature": "ET MALWARE Possible Malware Outbound",
    "category": "Potentially Bad Traffic",
    "severity": 2
  }
}
```

**Fields in the Alert Log:**

- **timestamp**: The date and time when the alert was generated.
- **event_type**: Indicates the type of event, in this case, `alert`.
- **src_ip**: Source IP address of the traffic.
- **src_port**: Source port number.
- **dest_ip**: Destination IP address of the traffic.
- **dest_port**: Destination port number.
- **proto**: Protocol used (e.g., TCP).
- **alert**: Contains details about the alert:
    - **action**: Action taken (e.g., allowed).
    - **gid**: Generator ID.
    - **signature_id**: ID of the signature that triggered the alert.
    - **rev**: Revision number of the signature.
    - **signature**: Description of the signature.
    - **category**: Category of the alert.
    - **severity**: Severity level of the alert.

#### Network Telemetry Logs

Network telemetry logs contain information about network traffic flows. These logs are useful for understanding what is happening on a network, such as connections being made to specific ports.

**Example of a Network Telemetry Log:**

```json
{
  "timestamp": "2023-01-01T12:34:56.789012Z",
  "event_type": "http",
  "src_ip": "192.168.1.10",
  "dest_ip": "10.0.0.5",
  "proto": "TCP",
  "http": {
    "hostname": "example.com",
    "url": "/index.html",
    "http_user_agent": "Mozilla/5.0",
    "http_content_type": "text/html",
    "status": 200,
    "length": 1234
  }
}

```

**Fields in the Network Telemetry Log:**

- **timestamp**: The date and time when the log was generated.
- **event_type**: Indicates the type of event, in this case, `http`.
- **src_ip**: Source IP address of the traffic.
- **dest_ip**: Destination IP address of the traffic.
- **proto**: Protocol used (e.g., TCP).
- **http**: Contains details about the HTTP request:
    - **hostname**: The website that was accessed.
    - **url**: The specific URL that was requested.
    - **http_user_agent**: The software used to access the website (e.g., web browser).
    - **http_content_type**: The type of content returned by the HTTP request (e.g., text/html).
    - **status**: HTTP status code of the request (e.g., 200).
    - **length**: The length of the response in bytes.

### Summary

Understanding Suricata logs is crucial for effective network monitoring and security analysis. Alert logs provide details on security-relevant events, while network telemetry logs offer insights into general network traffic. As a security analyst, interpreting these logs allows you to build a comprehensive story during an investigation and respond effectively to potential threats.

Overview of Suricata
--------------------

So far, you've learned about detection signatures and you were introduced to Suricata, an intrusion detection system (IDS). In this reading, you’ll explore more about Suricata. You'll also learn about the value of writing customized signatures and configuration. This is an important skill to build in your cybersecurity career because you might be tasked with deploying and maintaining IDS tools.

Introduction to Suricata
------------------------

[**Suricata**](https://suricata.io/) is an open-source intrusion detection system, intrusion prevention system, and network analysis tool.

### Suricata Features

There are three main ways Suricata can be used:

*   **Intrusion detection system (IDS)**: As a network-based IDS, Suricata can monitor network traffic and alert on suspicious activities and intrusions. Suricata can also be set up as a host-based IDS to monitor the system and network activities of a single host like a computer.
    
*   **Intrusion prevention system (IPS)**: Suricata can also function as an intrusion prevention system (IPS) to detect and block malicious activity and traffic. Running Suricata in IPS mode requires additional configuration such as enabling IPS mode.
    
*   **Network security monitoring (NSM)**: In this mode, Suricata helps keep networks safe by producing and saving relevant network logs. Suricata can analyse live network traffic, existing packet capture files, and create and save full or conditional packet captures. This can be useful for forensics, incident response, and for testing signatures. For example, you can trigger an alert and capture the live network traffic to generate traffic logs, which you can then analyse to refine detection signatures.
    

Rules
-----

Rules or signatures are used to identify specific patterns, behaviour, and conditions of network traffic that might indicate malicious activity. The terms rule and signature are often used interchangeably in Suricata. Security analysts use **signatures**, or patterns associated with malicious activity, to detect and alert on specific malicious activity. Rules can also be used to provide additional context and visibility into systems and networks, helping to identify potential security threats or vulnerabilities.

Suricata uses **signature analysis**, which is a detection method used to find events of interest. Signatures consist of three components:

*   **Action**: The first component of a signature. It describes the action to take if network or system activity matches the signature. Examples include: alert, pass, drop, or reject.
    
*   **Header**: The header includes network traffic information like source and destination IP addresses, source and destination ports, protocol, and traffic direction.
    
*   **Rule options**: The rule options provide you with different options to customize signatures.
    

Here's an example of a Suricata signature:

plaintext

Copy code

`alert http $HOME_NET any -> $EXTERNAL_NET any (msg:"GET on wire"; flow:established; content:"GET"; sid:1; rev:1;)`

**Note:** Rule order refers to the order in which rules are evaluated by Suricata. Rules are processed in the order in which they are defined in the configuration file. However, Suricata processes rules in a different default order: pass, drop, reject, and alert. Rule order affects the final verdict of a packet especially when conflicting actions such as a drop rule and an alert rule both match on the same packet.

### Custom Rules

Although Suricata comes with pre-written rules, it is highly recommended that you modify or customize the existing rules to meet your specific security requirements.

There is no one-size-fits-all approach to creating and modifying rules. This is because each organization's IT infrastructure differs. Security teams must extensively test and modify detection signatures according to their needs.

Creating custom rules helps to tailor detection and monitoring. Custom rules help to minimize the amount of false positive alerts that security teams receive. It's important to develop the ability to write effective and customized signatures so that you can fully leverage the power of detection technologies.

Configuration File
------------------

Before detection tools are deployed and can begin monitoring systems and networks, you must properly configure their settings so that they know what to do. A **configuration file** is a file used to configure the settings of an application. Configuration files let you customize exactly how you want your IDS to interact with the rest of your environment.

Suricata's configuration file is `suricata.yaml`, which uses the YAML file format for syntax and structure.

Log Files
---------

There are two log files that Suricata generates when alerts are triggered:

*   **eve.json**: The eve.json file is the standard Suricata log file. This file contains detailed information and metadata about the events and alerts generated by Suricata stored in JSON format. For example, events in this file contain a unique identifier called `flow_id` which is used to correlate related logs or alerts to a single network flow, making it easier to analyse network traffic. The eve.json file is used for more detailed analysis and is considered to be a better file format for log parsing and SIEM log ingestion.
    
*   **fast.log**: The fast.log file is used to record minimal alert information including basic IP address and port details about the network traffic. The fast.log file is used for basic logging and alerting and is considered a legacy file format and is not suitable for incident response or threat hunting tasks.
    

The main difference between the eve.json file and the fast.log file is the level of detail that is recorded in each. The fast.log file records basic information, whereas the eve.json file contains additional verbose information.

Key Takeaways
-------------

In this reading, you explored some of Suricata's features, rules syntax, and the importance of configuration. Understanding how to configure detection technologies and write effective rules will provide you with clear insight into the activity happening in an environment so that you can improve detection capability and network visibility. Go ahead and start practicing using Suricata in the upcoming activity!


---

# Overview of security information event management (SIEM) tools

## Security Information and Event Management (SIEM) Tools

As a security analyst, you need to quickly access relevant data to perform your duties. Whether triaging alerts, monitoring systems, or analyzing log data during incident investigations, a SIEM is the tool for the job.

### Overview of SIEM

A Security Information and Event Management (SIEM) application collects and analyses log data to monitor critical activities in an organization. SIEM tools perform the following key functions:

1. **Collect and Process Data**: SIEM tools gather enormous amounts of data generated by devices and systems across an environment.
2. **Normalize Data**: SIEM tools format raw data consistently and include only relevant event information, making it easier for security analysts to read and analyse.
3. **Index Data**: SIEM tools index the processed data so it can be accessed quickly through search functionalities.

### SIEM Data Collection Process

1. **Collection**: SIEM tools gather data from multiple sources, including network devices, servers, and applications.
2. **Processing**: The collected data is normalized to ensure consistent formatting and to extract relevant event information.
3. **Indexing**: The processed data is indexed, allowing analysts to access and search through the data efficiently.

### Benefits of SIEM

- **Quick Access to Data**: SIEM tools allow for fast retrieval and analysis of data flows across networks.
- **Data Normalization**: By normalizing data, SIEM tools ensure consistency in data formatting, making it easier for analysts to interpret the data.
- **Comprehensive Monitoring**: SIEM tools provide a centralized view of security data from multiple sources, enabling thorough monitoring of an organization's environment.

### Common SIEM Tools

#### Splunk

Splunk is a data analysis platform that offers SIEM solutions through Splunk Enterprise Security. Key features include:

- **Data Collection**: Splunk collects data from various sources.
- **Data Processing**: The collected data is processed and stored in an index.
- **Data Access**: Analysts can search, analyse, and visualize the indexed data using Splunk's search functionalities.

#### Chronicle

Chronicle is Google Cloud's SIEM solution. Key features include:

- **Data Forwarding**: Security data is forwarded to Chronicle.
- **Data Normalization**: The forwarded data is cleaned and normalized for easier processing.
- **Data Access**: The normalized data becomes available for search, analysis, and visualization through a search bar.

### Key Takeaways

- SIEM tools are essential for security analysts to efficiently access and analyse security data.
- Understanding how to use and adapt to different SIEM tools is crucial for effective security monitoring and incident response.
- SIEM tools like Splunk and Chronicle provide comprehensive solutions for data collection, normalization, and indexing, enabling quick and thorough data analysis.

### Resources for More Information

- [Splunk Enterprise Security](https://www.splunk.com/en_us/products/enterprise-security.html)
- [Google Chronicle](https://cloud.google.com/chronicle)

These resources will help you gain a deeper understanding of the functionalities and features offered by these SIEM tools.

## Log Sources and Log Ingestion

In this reading, you'll explore more on the importance of log ingestion. You may recall that **security information and event management** (**SIEM**) tools collect and analyse log data to monitor critical activities in an organization. You also learned about **log analysis,** which is the process of examining logs to identify events of interest. Understanding how log sources are ingested into SIEM tools is important because it helps security analysts understand the types of data that are being collected, and can help analysts identify and prioritize security incidents.

### SIEM Process Overview

Previously, you covered the SIEM process. As a refresher, the process consists of three steps:

1. **Collect and Aggregate Data**: SIEM tools collect event data from various data sources.
2. **Normalize Data**: Event data that's been collected becomes normalized. Normalization converts data into a standard format so that data is structured in a consistent way and becomes easier to read and search. While data normalization is a common feature in many SIEM tools, it's important to note that SIEM tools vary in their data normalization capabilities.
3. **analyse Data**: After the data is collected and normalized, SIEM tools analyse and correlate the data to identify common patterns that indicate unusual activity.

This reading focuses on the first step of this process, the collection and aggregation of data.

### Log Ingestion

Data is required for SIEM tools to work effectively. SIEM tools must first collect data using log ingestion. Log ingestion is the process of collecting and importing data from log sources into a SIEM tool. Data comes from any source that generates log data, like a server.

In log ingestion, the SIEM creates a copy of the event data it receives and retains it within its own storage. This copy allows the SIEM to analyse and process the data without directly modifying the original source logs. The collection of event data provides a centralized platform for security analysts to analyse the data and respond to incidents. This event data includes authentication attempts, network activity, and more.

### Log Forwarders

There are many ways SIEM tools can ingest log data. For instance, you can manually upload data or use software to help collect data for log ingestion. Manually uploading data may be inefficient and time-consuming because networks can contain thousands of systems and devices. Hence, it's easier to use software that helps collect data.

A common way that organizations collect log data is to use log forwarders. Log forwarders are software that automate the process of collecting and sending log data. Some operating systems have native log forwarders. If you are using an operating system that does not have a native log forwarder, you would need to install third-party log forwarding software on a device. After installing it, you'd configure the software to specify which logs to forward and where to send them. For example, you can configure the logs to be sent to a SIEM tool. The SIEM tool would then process and normalize the data. This allows the data to be easily searched, explored, correlated, and analysed.

**Note**: Many SIEM tools utilize their own proprietary log forwarders. SIEM tools can also integrate with open-source log forwarders. Choosing the right log forwarder depends on many factors such as the specific requirements of your system or organization, compatibility with your existing infrastructure, and more.

### Key Takeaways

SIEM tools require data to be effective. As a security analyst, you will utilize SIEM tools to access events and analyse logs when you're investigating an incident. In your security career, you may even be tasked with configuring a SIEM to collect log data. It's important that you understand how data is ingested into SIEM tools because this enables you to understand where log sources come from which can help you identify the source of a security incident.

## Query for Events with Splunk

Now that we've reviewed how a SIEM works, let's learn how to search and query events in a SIEM database. Data that's been imported into a SIEM can be accessed by entering queries into the SIEM's search engine. Massive amounts of data can be stored in a SIEM database. Some of this data may date back years. This can make searching for security events challenging.

### Importance of Specific Queries

For example, let's say you're searching to find a failed login event. You search for the event using the keywords: `failed login`. This is a very broad query, which can return thousands of results. Broad search queries like this slow down the response times of a search engine since it's searching across all the indexed data. But, if you specify additional parameters, like an event ID and a date and time range, you can narrow down the search to get faster results. It's important that search queries are specific, so that you can find exactly what you're looking for and save time in the search process.

### Splunk's Search Processing Language (SPL)

Different SIEM tools use different search methods. For example, Splunk uses its own query language called Search Processing Language, or SPL for short. SPL has many different search options you can use to optimize search results, so that you can get the data you're looking for.

### Performing a Raw Log Search in Splunk Cloud

#### Example Scenario

Let's demonstrate a raw log search in Splunk Cloud for events that reference errors or failures for a fictional online store called Buttercup Games.

#### Steps:

1. **Enter the Query**:
    
    - Use the search bar to type in the query:
        
        `buttercupgames error OR fail*`
        
    - This search specifies the index (`buttercupgames`) and the search terms (`error` OR `fail`). The Boolean operator `OR` ensures that both of the keywords will be searched. The asterisk at the end of the term `fail*` is known as a wildcard. This means it will search for all possible endings that contain the term `fail`.
2. **Select a Time Range**:
    
    - Use the time range picker to specify the time range. For example, search for data from the last 30 days.
3. **Review Search Results**:
    
    - Under the search bar, review the search results.
    - **Timeline**: This gives a visual representation of the number of events over a period, helpful for identifying event patterns such as peaks in activity.
    - **Events Viewer**: This gives a list of events that match the search. Notice how the search terms (`buttercupgames` and `error`) are highlighted in each event. Each event has a timestamp and raw logged data.
4. **Exclude Specific Data Sources**:
    
    - To exclude specific data sources, such as hosts, click on the information related to the data source. For example, to exclude host `www1`:
        
        `host!=www1`
        
    - The new search results will not contain `www1` as a host but will contain other hosts like `www2` and `www3`.

#### Example Search Output

- **Search Query**:
    
    `buttercupgames error OR fail*`
    
- **Filtered Query** (excluding `www1`):
    
    `buttercupgames error OR fail* host!=www1`
    

### Key Takeaways

- Effective queries are crucial for quickly accessing relevant data in a SIEM.
- Use specific search parameters to narrow down search results.
- Splunk's Search Processing Language (SPL) provides various search options to optimize search performance.

## Query for Events with Chronicle

Chronicle allows you to search and filter log data. Chronicle uses the YARA-L language to define rules for detection, a computer language used to create rules for searching through ingested log data. For example, you can use YARA-L to write a rule to detect specific activities related to the exfiltration of valuable data.

### Search Methods in Chronicle

Using Chronicle's search field, you can search for fields like hostname, domain, IP, URL, email, username, or file hash. There are two primary search methods in Chronicle:

1. **UDM Search (Unified Data Model)**: Searches through normalized data.
2. **Raw Log Search**: Searches through the logs which have not been normalized.

### Understanding Normalization

From our earlier discussion on the SIEM process, you may recall that raw logs get processed during the normalization step. During normalization, all of the relevant information from raw logs gets extracted and formatted, making the data easier to search. A reason we might need to search raw logs is to find data that may not have been included in the normalized logs, like specific fields which have not been normalized, or to troubleshoot data ingestion problems.

### Example: UDM Search for a Failed Login

Let's examine a UDM search for a failed login using Chronicle.

1. **Open the Structured Query Builder**:
    - Click on the structured query builder icon to perform a UDM search.
2. **Enter the Search Query**:
    - Type in the search:
        
        `metadata.event_type = "USER_LOGIN" AND security_result.action = "BLOCK"`
        
3. **Break Down the UDM Search**:
    - **metadata.event_type**: Specifies the event's type. In this case, `USER_LOGIN` indicates an authentication activity event.
    - **AND**: A logical operator that tells the search engine to contain both terms.
    - **security_result.action**: Specifies a security action such as allow or block. Here, `BLOCK` means the user login was blocked or failed.
4. **Run the Query**:
    - Press the query button to execute the search.

### Interpreting Search Results

After executing the query, the following elements are presented:

1. **Search Terms**:
    - Displayed under UDM Search.
2. **Timeline**:
    - A bar graph visualizing the failed login events over a period, providing a snapshot of the activity over time.
3. **Event List**:
    - A list of events with timestamps associated with the search. Each event includes details such as the asset (device name) and the username. For example, a failed login for a user named `alice`.
4. **Raw Logs**:
    - Click an event to open the raw log associated with it for more detailed information.
5. **Quick Filters**:
    - Additional fields or values to filter search results further. For instance, selecting `target.ip` provides a list of IP addresses. Clicking an IP address filters the results to include only events involving that IP address.

### Key Takeaways

- **Effective Search Queries**: Using specific search parameters helps to narrow down search results, making it easier to find relevant data quickly.
- **Normalized vs. Raw Logs**: Understanding the difference between normalized and raw logs helps in troubleshooting and finding specific information that may not be included in normalized data.
- **Using Filters**: Quick filters help refine search results to target specific data points, saving time and improving search efficiency.


## Search Methods with SIEM Tools

So far, you’ve learned about how you can use **security information and event management (SIEM)** tools to search for security events such as failed login attempts. Remember, SIEM is an application that collects and analyses log data to monitor critical activities in an organization. In this reading, you’ll examine how SIEM tools like Splunk and Chronicle use different search methods to find, filter, and transform search results.

Not all organizations use the same SIEM tool to gather and centralize their security data. As a security analyst, you’ll need to be ready to learn how to use different SIEM tools. It’s important to understand the different types of searches you can perform using SIEM tools so that you can find relevant event data to support your security investigations.

## Splunk Searches

As you’ve learned, Splunk has its own querying language called **Search Processing Language (SPL)**. SPL is used to search and retrieve events from indexes using Splunk’s Search & Reporting app. An SPL search can contain many different commands and arguments. For example, you can use commands to transform your search results into a chart format or filter results for specific information.

![Splunk Cloud's search page.](https://d3c33hcgiwev3.cloudfront.net/imageAssetProxy.v1/zmjvpMvASVuLzBl6p1-KJg_48cf882e1ea14f6ca2f3ceee91e1f2e1_cIW5xo7oKZMktF78z_u5eTeEJANj9wPgAG39QVCd8PDuvdrztqt2N1fJMbJOFms1QoIgAk0YNgHWjR1LQMLg__bhWqMMWmWke6kQmoWLpyxM5eVwNDyW7_2KttYjVSz2fYPCX4arj1TUHKrSfANwCU8?expiry=1716595200000&hmac=aPaqivEoQ3GeIwz1Q4DptbN0i9D6pNJVXZp0JwESjwU)

Here is an example of a basic SPL search that is querying an index for a failed event:

`index=main fail`

- `index=main`: This is the beginning of the search command that tells Splunk to retrieve events from an index named main. An index stores event data that's been collected and processed by Splunk.
- `fail`: This is the search term. This tells Splunk to return any event that contains the term fail.

Knowing how to effectively use SPL has many benefits. It helps shorten the time it takes to return search results. It also helps you obtain the exact results you need from various data sources. SPL supports many different types of searches that are beyond the scope of this reading. If you would like to learn more about SPL, explore [Splunk's Search Reference](https://docs.splunk.com/Documentation/Splunk/9.0.2/SearchReference/UnderstandingSPLsyntax).

### Pipes

Previously, you might have learned about how piping is used in the Linux bash shell. As a refresher, piping sends the output of one command as the input to another command.

SPL also uses the pipe character `|` to separate the individual commands in the search. It's also used to chain commands together so that the output of one command combines into the next command. This is useful because you can refine data in various ways to get the results you need using a single command.

Here is an example of two commands that are piped together:

`index=main fail| chart count by host`

- `index=main fail`: This is the beginning of the search command that tells Splunk to retrieve events from an index named main for events containing the search term fail.
- `|`: The pipe character separates and chains the two commands index=main and chart count by host. This means that the output of the first command index=main is used as the input of the second command chart count by host.
- `chart count by host`: This command tells Splunk to transform the search results by creating a chart according to the count or number of events. The argument by host tells Splunk to list the events by host, which are the names of the devices the events come from. This command can be helpful in identifying hosts with excessive failure counts in an environment.

### Wildcard

A **wildcard** is a special character that can be substituted with any other character. A wildcard is usually symbolized by an asterisk character `*`. Wildcards match characters in string values. In Splunk, the wildcard that you use depends on the command that you are using the wildcard with. Wildcards are useful because they can help find events that contain data that is similar but not entirely identical. Here is an example of using a wildcard to expand the search results for a search term:

`index=main fail*`

- `index=main`: This command retrieves events from an index named main.
- `fail*`: The wildcard after fail represents any character. This tells Splunk to search for all possible endings that contain the term fail. This expands the search results to return any event that contains the term fail such as “failed” or “failure”.

**Pro tip**: Double quotations are used to specify a search for an exact phrase or string. For example, if you want to only search for events that contain the exact phrase `login failure`, you can enclose the phrase in double quotations `"login failure"`. This search will match only events that contain the exact phrase `login failure` and not other events that contain the words failure or login separately.

## Chronicle Searches

In Chronicle, you can search for events using the Search field. You can also use Procedural Filtering to apply filters to a search to further refine the search results. For example, you can use Procedural Filtering to include or exclude search results that contain specific information relating to an event type or log source. There are two types of searches you can perform to find events in Chronicle, a Unified Data Mode (UDM) Search or a Raw Log Search.

![Chronicle's home page.](https://d3c33hcgiwev3.cloudfront.net/imageAssetProxy.v1/aM2yKauvThC6hDgvWmzbSQ_0e4167e2b3ab436d92d7cab63fc844e1_7Gwfz8thmYUWWdxjQiQtHM6omUL7OLjOSSD_fShq4yrmkr7sAJs4pBDBJ2Azy26HdkyF3K50mIQEtIqW4FaA2F-eN9G1Ev4WM_Drze0i3-5-Et_l51y9nTnh9eHqQFitE0f5Yzr5YsTzf7qL-MQbDHI?expiry=1716595200000&hmac=Fo8lZox1ztQnekyiCx545e3tc2lDsRNaPKcy0raHfi8)

### Unified Data Model (UDM) Search

The UDM Search is the default search type used in Chronicle. You can perform a UDM search by typing your search, clicking on “Search,” and selecting “UDM Search.” Through a UDM Search, Chronicle searches security data that has been ingested, parsed, and normalized. A UDM Search retrieves search results faster than a Raw Log Search because it searches through indexed and structured data that’s normalized in UDM.

A UDM Search retrieves events formatted in UDM and these events contain UDM fields. There are many different types of UDM fields that can be used to query for specific information from an event. Discussing all of these UDM fields is beyond the scope of this reading, but you can learn more about UDM fields by exploring [Chronicle's UDM field list](https://cloud.google.com/chronicle/docs/reference/udm-field-list). Know that all UDM events contain a set of common fields including:

- **Entities**: Entities are also known as nouns. All UDM events must contain at least one entity. This field provides additional context about a device, user, or process that’s involved in an event. For example, a UDM event that contains entity information includes the details of the origin of an event such as the hostname, the username, and IP address of the event.
- **Event metadata**: This field provides a basic description of an event, including what type of event it is, timestamps, and more.
- **Network metadata**: This field provides information about network-related events and protocol details.
- **Security results**: This field provides the security-related outcome of events. An example of a security result can be an antivirus software detecting and quarantining a malicious file by reporting "virus detected and quarantined."

Here’s an example of a simple UDM search that uses the event metadata field to locate events relating to user logins:

`metadata.event_type = “USER_LOGIN”`

- `metadata.event_type = “USER_LOGIN”`: This UDM field metadata.event_type contains information about the event type. This includes information like timestamp, network connection, user authentication, and more. Here, the event type specifies USER_LOGIN, which searches for events relating to authentication.

Using just the metadata fields, you can quickly start searching for events. As you continue practicing searching in Chronicle using UDM Search, you will encounter more fields. Try using these fields to form specific searches to locate different events.

### Raw Log Search

If you can't find the information you are searching for through the normalized data, using a Raw Log Search will search through the raw, unparsed logs. You can perform a Raw Log Search by typing your search, clicking on “Search,” and selecting “Raw Log Search.” Because it is searching through raw logs, it takes longer than a structured search. In the Search field, you can perform a Raw Log Search by specifying information like usernames, filenames, hashes, and more. Chronicle will retrieve events that are associated with the search.

**Pro tip**: Raw Log Search supports the use of regular expressions, which can help you narrow down a search to match on specific patterns.

## Key Takeaways

SIEM tools like Splunk and Chronicle have their own methods for searching and retrieving event data. As a security analyst, it's important to understand how to leverage these tools to quickly and efficiently find the information you need. This will allow you to explore data in ways that support detecting threats, as well as rapidly responding to security incidents.
  
  ---
  
  # Glossary terms from module 4

**Anomaly-based analysis:** A detection method that identifies abnormal behaviour 

**Array:** A data type that stores data in a comma-separated ordered list

**Common Event Format (CEF):** A log format that uses key-value pairs to structure data and identify fields and their corresponding values

**Configuration file:** A file used to configure the settings of an application

**Endpoint:** Any device connected on a network

**Endpoint detection and response (EDR):** An application that monitors an endpoint for malicious activity

**False positive:** An alert that incorrectly detects the presence of a threat

**Host-based intrusion detection system (HIDS):** An application that monitors the activity of the host on which it’s installed 

**Intrusion detection systems (IDS)**: An application that monitors system activity and alerts on possible intrusions

**Key-value pair:** A set of data that represents two linked items: a key, and its corresponding value

**Log:** A record of events that occur within an organization’s systems

**Log analysis:** The process of examining logs to identify events of interest 

**Log management:** The process of collecting, storing, analyzing, and disposing of log data

**Logging:** The recording of events occurring on computer systems and networks

**Network-based intrusion detection system (NIDS):** An application that collects and monitors network traffic and network data

**Object:** A data type that stores data in a comma-separated list of key-value pairs

**Search Processing Language (SPL)**: Splunk’s query language

**Security information and event management (SIEM)**_:_ An application that collects and analyses log data to monitor critical activities in an organization 

**Signature:** A pattern that is associated with malicious activity

**Signature analysis:** A detection method used to find events interest

**Suricata**: An open-source intrusion detection system, intrusion prevention system, and network analysis tool

**Telemetry:** The collection and transmission of data for analysis

**Wildcard**: A special character that can be substituted with any other character

**YARA-L:** A computer language used to create rules for searching through ingested log data

**Zero-day:** An exploit that was previously unknown